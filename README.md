# MeetGPT ‚Äì Transcri√ß√£o de Reuni√µes üéôÔ∏è
[English version](README.en.md)

Aplica√ß√£o Web em Python para capturar √°udio de reuni√µes em tempo real, transcrever com Whisper e gerar resumos inteligentes com GPT. Ideal para registrar decis√µes, facilitar revis√µes e servir como base para assistentes virtuais e solu√ß√µes de acessibilidade.

## Sum√°rio
- [Vis√£o geral](#vis√£o-geral)
- [Funcionalidades](#funcionalidades)
- [Como funciona](#como-funciona)
- [Arquitetura e estrutura de pastas](#arquitetura-e-estrutura-de-pastas)
- [Tecnologias](#tecnologias)
- [Pr√©-requisitos](#pr√©-requisitos)
- [Instala√ß√£o](#instala√ß√£o)
- [Configura√ß√£o](#configura√ß√£o)
- [Execu√ß√£o](#execu√ß√£o)
- [Uso](#uso)
- [Personaliza√ß√£o](#personaliza√ß√£o)
- [Boas pr√°ticas e seguran√ßa](#boas-pr√°ticas-e-seguran√ßa)
- [Solu√ß√£o de problemas](#solu√ß√£o-de-problemas)
- [Roadmap](#roadmap)
- [Contribui√ß√£o](#contribui√ß√£o)
- [Autor](#autor)
- [Licen√ßa](#licen√ßa)

---

## Vis√£o geral
O MeetGPT √© um Web App constru√≠do com Streamlit que:
- Captura √°udio do microfone via WebRTC.
- Transcreve o √°udio em tempo real com Whisper (OpenAI).
- Gera resumos objetivos com pontos de acordos utilizando modelos GPT.
- Armazena e organiza o hist√≥rico de reuni√µes localmente.

Ao final, voc√™ ter√° um projeto robusto que integra captura de √°udio, processamento com IA e apresenta√ß√£o amig√°vel.

---

## Funcionalidades 
- Grava√ß√£o de √°udio direto do navegador (microfone).
- Transcri√ß√£o incremental a cada ~5 segundos.
- Gera√ß√£o autom√°tica de resumo com:
  - Texto corrido (at√© 300 caracteres).
  - Lista de acordos/combina√ß√µes em bullet points.
- Organiza√ß√£o de reuni√µes por data/hora com t√≠tulo.
- Visualiza√ß√£o do resumo e da transcri√ß√£o completa.

---

## Como funciona
Fluxo principal do `app.py`:
1. Captura de √°udio com `streamlit-webrtc` (modo SENDONLY).
2. Agrega√ß√£o dos frames de √°udio com `pydub`:
   - `audio.mp3` (acumulado da reuni√£o)
   - `audio_temp.mp3` (janela incremental)
3. A cada ~5 segundos, envia `audio_temp.mp3` para transcri√ß√£o:
   - `OpenAI Whisper (model="whisper-1")`
   - Idioma padr√£o: `pt`
4. Concatena a transcri√ß√£o incremental e exibe em tela, salvando em `transcricao.txt`.
5. Na aba de reuni√µes salvas:
   - Permite adicionar um t√≠tulo.
   - Gera e exibe o resumo com `chat.completions` (modelo padr√£o `gpt-3.5-turbo-1106`) usando um prompt estruturado.
   - Salva o resumo em `resumo.txt`.

---

## Arquitetura e estrutura de pastas
- Interface: Streamlit (duas abas)
  - Gravar Reuni√£o
  - Ver transcri√ß√µes salvas
- Persist√™ncia local: pasta `arquivos/` na raiz do projeto.

Estrutura de sa√≠da por reuni√£o:
```
arquivos/
‚îî‚îÄ‚îÄ YYYY_MM_DD_HH_MM_SS/
    ‚îú‚îÄ‚îÄ audio.mp3          # √°udio completo acumulado
    ‚îú‚îÄ‚îÄ audio_temp.mp3     # √°udio da janela de ~5s (sobrescrito durante a grava√ß√£o)
    ‚îú‚îÄ‚îÄ transcricao.txt    # transcri√ß√£o completa
    ‚îú‚îÄ‚îÄ resumo.txt         # resumo gerado por GPT
    ‚îî‚îÄ‚îÄ titulo.txt         # t√≠tulo definido pelo usu√°rio
```

---

## Tecnologias 
- Python
- Streamlit
- streamlit-webrtc (WebRTC no navegador)
- pydub (manipula√ß√£o de √°udio) + FFmpeg
- OpenAI API (Whisper + GPT)
- python-dotenv (carregamento de vari√°veis do .env)

---

## Pr√©-requisitos
- Python 3.9+ (recomendado)
- FFmpeg instalado e dispon√≠vel no PATH (necess√°rio para o pydub)
- Chave de API da OpenAI

Instala√ß√£o do FFmpeg:
- macOS (Homebrew): `brew install ffmpeg`
- Ubuntu/Debian: `sudo apt-get update && sudo apt-get install -y ffmpeg`
- Windows (Chocolatey): `choco install ffmpeg`

---

## Instala√ß√£o 
1. Clone o reposit√≥rio:
   ```
   git clone https://github.com/<owner>/<repo>.git
   cd <repo>
   ```

2. Crie e ative um ambiente virtual (opcional, mas recomendado):
   - macOS/Linux:
     ```
     python3 -m venv .venv
     source .venv/bin/activate
     ```
   - Windows (PowerShell):
     ```
     python -m venv .venv
     .venv\Scripts\Activate.ps1
     ```

3. Instale as depend√™ncias:
   ```
   pip install -r requirements.txt
   ```
   Caso n√£o exista um `requirements.txt`, instale manualmente:
   ```
   pip install streamlit streamlit-webrtc pydub openai python-dotenv
   ```

---

## Configura√ß√£o
Crie um arquivo `.env` na raiz do projeto com sua chave da OpenAI:
```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

O projeto utiliza `python-dotenv` para carregar automaticamente essa vari√°vel no runtime.

---

## Execu√ß√£o
Inicie a aplica√ß√£o Streamlit:
```
streamlit run app.py
```

Acesse no navegador (geralmente):
```
http://localhost:8501
```

Permita o uso do microfone quando solicitado.

---

## Uso
1. Aba ‚ÄúGravar Reuni√£o‚Äù
   - Clique em ‚ÄúPermitir‚Äù quando o navegador solicitar acesso ao microfone.
   - Comece a falar. A cada ~5 segundos a transcri√ß√£o √© atualizada e salva.
   - Ao encerrar a fala/abaixar a guia, a sess√£o √© finalizada e os arquivos s√£o salvos em `arquivos/`.

2. Aba ‚ÄúVer transcri√ß√µes salvas‚Äù
   - Selecione uma reuni√£o pelo timestamp/t√≠tulo.
   - Se n√£o houver t√≠tulo, digite e clique em ‚ÄúSalvar‚Äù.
   - O resumo ser√° gerado automaticamente (se ainda n√£o existir) e exibido junto com a transcri√ß√£o completa.

---

## Personaliza√ß√£o
- Idioma da transcri√ß√£o:
  - Fun√ß√£o `transcreve_audio(caminho_audio, language='pt', ...)` ‚Äî altere `language`.
- Janela de transcri√ß√£o:
  - Intervalo determinado por `if agora - ultima_trancricao > 5:` ‚Äî ajuste para mais/menos segundos.
- Modelos OpenAI:
  - Transcri√ß√£o: `model='whisper-1'`.
  - Resumo (chat): `modelo='gpt-3.5-turbo-1106'` em `chat_openai`.
- Prompt de resumo:
  - Vari√°vel `PROMPT` no topo do arquivo ‚Äî edite regras (limite de caracteres, formato, etc).
- Armazenamento:
  - Pasta base `PASTA_ARQUIVOS` ‚Äî ajuste o caminho conforme necessidade.

Exemplo de `requirements.txt` sugerido:
```
streamlit>=1.33
streamlit-webrtc>=0.47
pydub>=0.25
openai>=1.0
python-dotenv>=1.0
```

---

## Boas pr√°ticas e seguran√ßa
- Nunca commit sua chave `OPENAI_API_KEY`.
- Use o arquivo `.env` local e adicione `.env` ao `.gitignore`.
- Se for lidar com dados sens√≠veis, considere:
  - Criptografia em repouso (por exemplo, transcri√ß√µes/resumos).
  - Termos e consentimento dos participantes.
  - Pol√≠ticas de reten√ß√£o e exclus√£o de dados.
- Custos: o uso da API da OpenAI √© pago por volume (tokens/√°udio). Monitore e defina limites.

---

## Solu√ß√£o de problemas
- Microfone n√£o funciona:
  - Verifique permiss√µes do navegador/OS para o site `localhost:8501`.
  - Use HTTPS em produ√ß√£o para WebRTC. Em localhost, HTTP normalmente funciona.
- Erro com pydub/FFmpeg:
  - Certifique-se de que o `ffmpeg` est√° instalado e acess√≠vel no PATH.
- Resumo n√£o √© gerado:
  - Verifique se `OPENAI_API_KEY` est√° definido e v√°lido.
  - Cheque eventuais limites de taxa (rate limit) da OpenAI.
- Lat√™ncia alta ou transcri√ß√£o irregular:
  - Reduza o intervalo de chunk (atual > 5s) ou melhore a rede/CPU.
- ‚Äúarquivos/‚Äù n√£o aparece:
  - A pasta √© criada automaticamente no primeiro uso. Verifique permiss√µes de escrita no diret√≥rio do projeto.

---

## Roadmap
- Exportar resumo/transcri√ß√£o em PDF/Markdown.
- Marca√ß√£o de speakers (diariza√ß√£o) e timestamps.
- Marcar a√ß√µes (to-dos) automaticamente com base no resumo.
- Suporte a idiomas multil√≠ngues com detec√ß√£o autom√°tica.
- Configura√ß√£o de STUN/TURN customizados para WebRTC em produ√ß√£o.
- Integra√ß√£o com banco de dados (SQLite/PostgreSQL) para hist√≥rico persistente.
- Autentica√ß√£o de usu√°rios.

---

## Contribui√ß√£o
Contribui√ß√µes s√£o bem-vindas!
- Abra uma issue descrevendo a melhoria/bug.
- Fa√ßa um fork, crie uma branch e envie um PR com uma descri√ß√£o clara.

Padr√£o sugerido de branch:
- `feat/<descri√ß√£o>`
- `fix/<descri√ß√£o>`
- `chore/<descri√ß√£o>`

---

## Autor
- @yagosamu
